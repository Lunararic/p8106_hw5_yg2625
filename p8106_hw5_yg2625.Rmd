---
title: "p8106_hw5_yg2625"
author: "Yue Gu"
date: "April 27, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ISLR)
library(caret)
library(e1071)
library(mlbench)

library(tidyverse)
set.seed(1)
```

**This problem involves the OJ data set which is part of the ISLR package. The data contains 1070 purchases where the customer either purchased Citrus Hill or Minute Maid Orange Juice. A number of characteristics of the customer and product are recorded. Use set.seed() for reproducibility. Create a training set containing a random sample of 800 observations, and a test set containing the remaining observations.**

## load data
```{r}
data(OJ)
oj_data = OJ %>% 
  janitor::clean_names()
  

# create a training set containing 800 obs, and a test set containing the remaining obs
set.seed(1)
rowTrain = createDataPartition(y = oj_data$purchase,
                               p = 799/1070,
                               list = F)
train_data = oj_data[rowTrain, ]
test_data = oj_data[-rowTrain, ]
```

# (a) Fit a support vector classifier (linear kernel) to the training data with Purchase as the response and the other variables as predictors. What are the training and test error rates?
```{r}
ctrl <- trainControl(method = "cv")

set.seed(1)
# fit model
svml.fit <- train(purchase ~ ., 
                  data = train_data, 
                  method = "svmLinear2",
                  preProcess = c("center", "scale"),
                  tuneGrid = data.frame(cost = exp(seq(-5,-1,len=50))),
                  trControl = ctrl)
# model output
svml.fit$finalModel
# best tunning parameter
svml.fit$bestTune
# Accuracy plot
ggplot(svml.fit, highlight = TRUE)
# training error rate
pred_train = predict(svml.fit)
mean(train_data$purchase != pred_train)
# test error rate
pred_test = predict(svml.fit, newdata = test_data, type = "raw")
mean(test_data$purchase != pred_test)
```
The training error is 0.161, the test error is 0.170.

# (b) Fit a support vector machine with a radial kernel to the training data. What are the training and test error rates?
```{r}
svmr.grid <- expand.grid(C = exp(seq(-5,2,len=20)),
                         sigma = exp(seq(-8,-1,len=10)))
set.seed(1) 
# fit model
svmr.fit <- train(purchase ~ ., train_data,
                  method = "svmRadial",
                  preProcess = c("center", "scale"),
                  tuneGrid = svmr.grid,
                  trControl = ctrl)
# model output
svmr.fit$finalModel
# best tunning parameter
svmr.fit$bestTune
# Accuracy plot
ggplot(svmr.fit, highlight = TRUE)
# trainning error rate
pred_train2 = predict(svmr.fit)
mean(train_data$purchase != pred_train2)
# test error rate
pred_test2 = predict(svmr.fit, newdata = test_data, type = "raw")
mean(test_data$purchase != pred_test2)
```
The training error rate is 0.156 and the test error rate is 0.170.

# (c) Which approach seems to give a better result on this data?
```{r}
resamp <- resamples(list(svmr = svmr.fit, svml = svml.fit))
bwplot(resamp)

# test data performance
pred.svml <- predict(svml.fit, newdata = test_data)
pred.svmr <- predict(svmr.fit, newdata = test_data)

# linear kernel
confusionMatrix(data = pred.svml, 
                reference = test_data$purchase)
# radial kernel
confusionMatrix(data = pred.svmr, 
                reference = test_data$purchase)
```
Based on the confusion matrix result, linear kernel and radial provides the same accracy and kappa on the test data. However, on the boxplot, svmr provides slightly larger kappa and accuracy compared to svml. Hence, radial kernel approach seems to give a better result on the data.
